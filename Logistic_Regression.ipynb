{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "78TscuXd2WC3"
      },
      "outputs": [],
      "source": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Here are detailed answers to your **Logistic Regression** questions, explained in **simple terms** for easy understanding.  \n",
        "\n",
        "---\n",
        "\n",
        "## **1. What is Logistic Regression, and how does it differ from Linear Regression?**  \n",
        "- **Logistic Regression** is a machine learning algorithm used for **classification tasks** (e.g., yes/no, spam/not spam).  \n",
        "- **Linear Regression** predicts **continuous values**, whereas **Logistic Regression** predicts **probabilities** between 0 and 1.  \n",
        "\n",
        "### **Key Difference:**  \n",
        "| Feature | Linear Regression | Logistic Regression |\n",
        "|---------|-----------------|-----------------|\n",
        "| **Type of Problem** | Regression (Continuous Output) | Classification (Categorical Output) |\n",
        "| **Equation** | \\( y = mx + b \\) | \\( y = \\frac{1}{1 + e^{-z}} \\) |\n",
        "| **Output** | Any real number | Between 0 and 1 |\n",
        "| **Use Case** | Predicting house prices | Predicting spam emails |\n",
        "\n",
        "---\n",
        "\n",
        "## **2. What is the mathematical equation of Logistic Regression?**  \n",
        "The **Logistic Regression equation** is:  \n",
        "\n",
        "\\[\n",
        "p = \\frac{1}{1 + e^{-(b_0 + b_1x_1 + b_2x_2 + ... + b_nx_n)}}\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- **\\( p \\)** = Probability of the positive class (e.g., \"yes\" or \"1\").  \n",
        "- **\\( b_0 \\)** = Intercept (bias).  \n",
        "- **\\( b_1, b_2, ..., b_n \\)** = Coefficients of the independent variables.  \n",
        "- **\\( x_1, x_2, ..., x_n \\)** = Features (input variables).  \n",
        "- **\\( e \\)** = Euler‚Äôs number (approx. **2.718**).  \n",
        "\n",
        "---\n",
        "\n",
        "## **3. Why do we use the Sigmoid function in Logistic Regression?**  \n",
        "The **Sigmoid function** is used to convert any real number into a **probability between 0 and 1**.  \n",
        "\n",
        "\\[\n",
        "\\sigma(z) = \\frac{1}{1 + e^{-z}}\n",
        "\\]\n",
        "\n",
        "**Why do we need it?**  \n",
        "- Ensures output is in the range **(0,1)**.  \n",
        "- Helps interpret the result as **probability**.  \n",
        "- Converts **linear predictions** into a **non-linear probability curve**.  \n",
        "\n",
        "---\n",
        "\n",
        "## **4. What is the cost function of Logistic Regression?**  \n",
        "Instead of using **Mean Squared Error (MSE)** (like in Linear Regression), Logistic Regression uses the **Log Loss (Binary Cross-Entropy) function**:\n",
        "\n",
        "\\[\n",
        "J(\\theta) = -\\frac{1}{m} \\sum \\left[ y \\log p + (1 - y) \\log (1 - p) \\right]\n",
        "\\]\n",
        "\n",
        "Where:  \n",
        "- \\( p \\) = Predicted probability.  \n",
        "- \\( y \\) = Actual class (0 or 1).  \n",
        "\n",
        "---\n",
        "\n",
        "## **5. What is Regularization in Logistic Regression? Why is it needed?**  \n",
        "**Regularization** prevents **overfitting** by adding a penalty to the loss function.  \n",
        "\n",
        "Two types:  \n",
        "1. **L1 Regularization (Lasso)** ‚Äì Shrinks some coefficients to zero, helping feature selection.  \n",
        "2. **L2 Regularization (Ridge)** ‚Äì Reduces the magnitude of coefficients but does not make them zero.  \n",
        "\n",
        "Regularization **prevents overfitting** by keeping model coefficients small.  \n",
        "\n",
        "---\n",
        "\n",
        "## **6. Explain the difference between Lasso, Ridge, and Elastic Net Regression.**  \n",
        "| Regularization Type | Effect on Coefficients | When to Use? |\n",
        "|---------------------|----------------------|--------------|\n",
        "| **Lasso (L1)** | Some coefficients become **zero** (feature selection). | When you want to remove irrelevant features. |\n",
        "| **Ridge (L2)** | Shrinks all coefficients but **keeps them nonzero**. | When all features are important. |\n",
        "| **Elastic Net** | Combination of L1 & L2 (some zero, some shrunk). | When you need **both** feature selection & shrinkage. |\n",
        "\n",
        "---\n",
        "\n",
        "## **7. When should we use Elastic Net instead of Lasso or Ridge?**  \n",
        "Use **Elastic Net** when:  \n",
        "- You have **many correlated variables**.  \n",
        "- You want **automatic feature selection** (L1 effect) while preventing too much shrinking (L2 effect).  \n",
        "\n",
        "---\n",
        "\n",
        "## **8. What is the impact of the regularization parameter (Œª) in Logistic Regression?**  \n",
        "- **High Œª** ‚Üí More penalty ‚Üí **Simpler model** (underfitting risk).  \n",
        "- **Low Œª** ‚Üí Less penalty ‚Üí **More complex model** (overfitting risk).  \n",
        "\n",
        "---\n",
        "\n",
        "## **9. What are the key assumptions of Logistic Regression?**  \n",
        "1. **Linear relationship between independent variables and log-odds.**  \n",
        "2. **No multicollinearity** (features should not be highly correlated).  \n",
        "3. **Independent observations.**  \n",
        "4. **Large sample size preferred.**  \n",
        "\n",
        "---\n",
        "\n",
        "## **10. What are some alternatives to Logistic Regression for classification tasks?**  \n",
        "- **Decision Trees**  \n",
        "- **Random Forest**  \n",
        "- **Support Vector Machines (SVM)**  \n",
        "- **Na√Øve Bayes**  \n",
        "- **Neural Networks**  \n",
        "\n",
        "---\n",
        "\n",
        "## **11. What are Classification Evaluation Metrics?**  \n",
        "- **Accuracy** = \\( \\frac{\\text{Correct Predictions}}{\\text{Total Predictions}} \\)  \n",
        "- **Precision** = \\( \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Positives}} \\)  \n",
        "- **Recall** = \\( \\frac{\\text{True Positives}}{\\text{True Positives} + \\text{False Negatives}} \\)  \n",
        "- **F1-score** = \\( \\frac{2 \\times \\text{Precision} \\times \\text{Recall}}{\\text{Precision} + \\text{Recall}} \\)  \n",
        "- **ROC-AUC Curve** = Measures probability of correct ranking.  \n",
        "\n",
        "---\n",
        "\n",
        "## **12. How does class imbalance affect Logistic Regression?**  \n",
        "If one class (e.g., \"yes\") is **much more frequent** than the other (\"no\"), the model may favor the dominant class.  \n",
        "\n",
        "**Solutions:**  \n",
        "- **Resampling** (Oversampling minority class or undersampling majority class).  \n",
        "- **Using different evaluation metrics** (Precision-Recall instead of Accuracy).  \n",
        "- **Adjusting class weights** (higher penalty for minority class misclassification).  \n",
        "\n",
        "---\n",
        "\n",
        "## **13. What is Hyperparameter Tuning in Logistic Regression?**  \n",
        "Hyperparameter tuning adjusts **C (inverse of Œª)** to control regularization.  \n",
        "- **Grid Search** ‚Äì Tries multiple values for the best performance.  \n",
        "- **Random Search** ‚Äì Selects random values to speed up tuning.  \n",
        "\n",
        "---\n",
        "\n",
        "## **14. What are different solvers in Logistic Regression? Which one should be used?**  \n",
        "| Solver | Best for | Notes |\n",
        "|--------|---------|-------|\n",
        "| **liblinear** | Small datasets | Uses coordinate descent. |\n",
        "| **saga** | Large datasets, L1/L2 Regularization | Supports sparse data. |\n",
        "| **lbfgs** | Default solver | Works well for most cases. |\n",
        "\n",
        "---\n",
        "\n",
        "## **15. How is Logistic Regression extended for multiclass classification?**  \n",
        "- **One-vs-Rest (OvR)** ‚Äì Trains separate binary classifiers for each class.  \n",
        "- **Softmax Regression** ‚Äì Assigns probability to **all classes at once**.  \n",
        "\n",
        "---\n",
        "\n",
        "## **16. Advantages & Disadvantages of Logistic Regression**  \n",
        "‚úÖ **Advantages:**  \n",
        "- Simple & fast.  \n",
        "- Works well for **binary classification**.  \n",
        "- Interpretable (coefficients have meaning).  \n",
        "\n",
        "‚ùå **Disadvantages:**  \n",
        "- Assumes **linear decision boundary**.  \n",
        "- Not suitable for **complex data** (images, text).  \n",
        "\n",
        "---\n",
        "\n",
        "## **17. Use Cases of Logistic Regression**  \n",
        "- **Medical Diagnosis** (Disease prediction).  \n",
        "- **Spam Detection** (Email classification).  \n",
        "- **Customer Churn Prediction**.  \n",
        "- **Fraud Detection** (Bank transactions).  \n",
        "\n",
        "---\n",
        "\n",
        "## **18. Difference Between Softmax Regression & Logistic Regression?**  \n",
        "| Feature | Logistic Regression | Softmax Regression |\n",
        "|---------|-----------------|-----------------|\n",
        "| **Task** | Binary Classification | Multiclass Classification |\n",
        "| **Output** | Probability of class 1 | Probability of multiple classes |\n",
        "\n",
        "---\n",
        "\n",
        "## **19. How to Choose Between OvR and Softmax for Multiclass?**  \n",
        "- **Use OvR** when classes are **imbalanced**.  \n",
        "- **Use Softmax** for **mutually exclusive** classes.  \n",
        "\n",
        "---\n",
        "\n",
        "## **20. How to Interpret Coefficients in Logistic Regression?**  \n",
        "- A **positive coefficient** ‚Üí Increases probability of class 1.  \n",
        "- A **negative coefficient** ‚Üí Decreases probability of class 1.  \n",
        "\n",
        "---\n",
        "\n",
        "Hope this helps! Let me know if you need any **simplifications or examples**. üòäüöÄ"
      ],
      "metadata": {
        "id": "rRfMZebG2Wxd"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.metrics import accuracy_score\n",
        "from sklearn.datasets import load_iris\n",
        "\n",
        "# Load dataset\n",
        "data = load_iris()\n",
        "X, y = data.data, data.target\n",
        "\n",
        "# Split into training and testing sets\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "\n",
        "# Train Logistic Regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and calculate accuracy\n",
        "y_pred = model.predict(X_test)\n",
        "accuracy = accuracy_score(y_test, y_pred)\n",
        "print(\"Model Accuracy:\", accuracy)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "BB-mdXp-28V8",
        "outputId": "25d4ab68-61b8-4568-dd58-9822e97ac37d"
      },
      "execution_count": 1,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train Logistic Regression with L1 Regularization (Lasso)\n",
        "lasso_model = LogisticRegression(penalty='l1', solver='liblinear', max_iter=1000)\n",
        "lasso_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred_lasso = lasso_model.predict(X_test)\n",
        "accuracy_lasso = accuracy_score(y_test, y_pred_lasso)\n",
        "print(\"L1 Regularization (Lasso) Accuracy:\", accuracy_lasso)\n",
        "\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "7SPOJv-k2_F2",
        "outputId": "0645c929-3437-4977-a2a3-276271ac07f7"
      },
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L1 Regularization (Lasso) Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression with L2 Regularization (Ridge)\n",
        "ridge_model = LogisticRegression(penalty='l2', solver='liblinear', max_iter=1000)\n",
        "ridge_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred_ridge = ridge_model.predict(X_test)\n",
        "accuracy_ridge = accuracy_score(y_test, y_pred_ridge)\n",
        "print(\"L2 Regularization (Ridge) Accuracy:\", accuracy_ridge)\n",
        "print(\"Model Coefficients:\", ridge_model.coef_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "S_s_TvwK2_oD",
        "outputId": "899b5768-7d8f-4ba8-ef3d-daf633a931dd"
      },
      "execution_count": 4,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "L2 Regularization (Ridge) Accuracy: 1.0\n",
            "Model Coefficients: [[ 0.3711229   1.409712   -2.15210117 -0.95474179]\n",
            " [ 0.49400451 -1.58897112  0.43717015 -1.11187838]\n",
            " [-1.55895271 -1.58893375  2.39874554  2.15556209]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train Logistic Regression with Elastic Net Regularization\n",
        "elastic_net_model = LogisticRegression(penalty='elasticnet', solver='saga', l1_ratio=0.5, max_iter=1000)\n",
        "elastic_net_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred_elastic = elastic_net_model.predict(X_test)\n",
        "accuracy_elastic = accuracy_score(y_test, y_pred_elastic)\n",
        "print(\"Elastic Net Regularization Accuracy:\", accuracy_elastic)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "t3SXN6sk3BTB",
        "outputId": "1bfa1aa9-403c-4038-946f-eed33e8c7199"
      },
      "execution_count": 6,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Elastic Net Regularization Accuracy: 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train Logistic Regression with multi_class='ovr'\n",
        "multiclass_model = LogisticRegression(multi_class='ovr', solver='lbfgs', max_iter=1000)\n",
        "multiclass_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred_multiclass = multiclass_model.predict(X_test)\n",
        "accuracy_multiclass = accuracy_score(y_test, y_pred_multiclass)\n",
        "print(\"Multiclass (OvR) Accuracy:\", accuracy_multiclass)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "feL8CYU63C34",
        "outputId": "c31ebcd5-19e2-46f7-952b-b078eddc276b"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Multiclass (OvR) Accuracy: 0.9666666666666667\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py:1256: FutureWarning: 'multi_class' was deprecated in version 1.5 and will be removed in 1.7. Use OneVsRestClassifier(LogisticRegression(..)) instead. Leave it to its default value to avoid this warning.\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import GridSearchCV\n",
        "\n",
        "# Define parameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2'],\n",
        "    'solver': ['liblinear']\n",
        "}\n",
        "\n",
        "# Perform Grid Search\n",
        "grid_search = GridSearchCV(LogisticRegression(max_iter=1000), param_grid, cv=5)\n",
        "grid_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and accuracy\n",
        "print(\"Best Parameters:\", grid_search.best_params_)\n",
        "print(\"Best Accuracy:\", grid_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "38Xcxj-w3EDU",
        "outputId": "50bf1844-042d-46d2-954d-3b1344c983ea"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'C': 10, 'penalty': 'l1', 'solver': 'liblinear'}\n",
            "Best Accuracy: 0.9583333333333334\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import StratifiedKFold, cross_val_score\n",
        "\n",
        "# Define Stratified K-Fold cross-validation\n",
        "skf = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "# Train and evaluate using cross-validation\n",
        "cv_scores = cross_val_score(LogisticRegression(max_iter=1000), X, y, cv=skf, scoring='accuracy')\n",
        "\n",
        "# Print average accuracy\n",
        "print(\"Stratified K-Fold CV Average Accuracy:\", cv_scores.mean())\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bGELBfXl3GXr",
        "outputId": "68b9b2d3-9ddd-4104-e200-f4331d6f9ddc"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Stratified K-Fold CV Average Accuracy: 0.9666666666666668\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "\n",
        "# Load dataset from CSV\n",
        "df = pd.read_csv(\"your_dataset.csv\")  # Replace with actual file path\n",
        "X = df.iloc[:, :-1].values  # All columns except last one\n",
        "y = df.iloc[:, -1].values   # Last column as target\n",
        "\n",
        "# Split and train Logistic Regression model\n",
        "X_train, X_test, y_train, y_test = train_test_split(X, y, test_size=0.2, random_state=42)\n",
        "csv_model = LogisticRegression(max_iter=1000)\n",
        "csv_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate\n",
        "y_pred_csv = csv_model.predict(X_test)\n",
        "accuracy_csv = accuracy_score(y_test, y_pred_csv)\n",
        "print(\"Accuracy from CSV dataset:\", accuracy_csv)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "Ow2q7LzY3IP8",
        "outputId": "cfaba0da-0be4-4178-885d-aba935f2cf81"
      },
      "execution_count": 13,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'your_dataset.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-13-537b89199da1>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      2\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;31m# Load dataset from CSV\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 4\u001b[0;31m \u001b[0mdf\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"your_dataset.csv\"\u001b[0m\u001b[0;34m)\u001b[0m  \u001b[0;31m# Replace with actual file path\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      5\u001b[0m \u001b[0mX\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m:\u001b[0m\u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m  \u001b[0;31m# All columns except last one\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0my\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdf\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0miloc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m-\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvalues\u001b[0m   \u001b[0;31m# Last column as target\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'your_dataset.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import RandomizedSearchCV\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Define hyperparameter grid\n",
        "param_grid = {\n",
        "    'C': [0.01, 0.1, 1, 10, 100],\n",
        "    'penalty': ['l1', 'l2', 'elasticnet', 'none'],\n",
        "    'solver': ['liblinear', 'saga']\n",
        "}\n",
        "\n",
        "# Perform Randomized Search\n",
        "random_search = RandomizedSearchCV(LogisticRegression(max_iter=1000), param_grid, n_iter=10, cv=5, random_state=42)\n",
        "random_search.fit(X_train, y_train)\n",
        "\n",
        "# Print best parameters and accuracy\n",
        "print(\"Best Parameters:\", random_search.best_params_)\n",
        "print(\"Best Accuracy:\", random_search.best_score_)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "l7Lp9wY74Pcz",
        "outputId": "a9194795-66ec-4168-f10b-b91927cd2107"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Best Parameters: {'solver': 'saga', 'penalty': 'l2', 'C': 10}\n",
            "Best Accuracy: 0.9666666666666668\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py:528: FitFailedWarning: \n",
            "30 fits failed out of a total of 50.\n",
            "The score on these train-test partitions for these parameters will be set to nan.\n",
            "If these failures are not expected, you can try to debug them by setting error_score='raise'.\n",
            "\n",
            "Below are more details about the failures:\n",
            "--------------------------------------------------------------------------------\n",
            "15 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1382, in wrapper\n",
            "    estimator._validate_params()\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 436, in _validate_params\n",
            "    validate_parameter_constraints(\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\", line 98, in validate_parameter_constraints\n",
            "    raise InvalidParameterError(\n",
            "sklearn.utils._param_validation.InvalidParameterError: The 'penalty' parameter of LogisticRegression must be a str among {'l1', 'l2', 'elasticnet'} or None. Got 'none' instead.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "10 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1193, in fit\n",
            "    solver = _check_solver(self.solver, self.penalty, self.dual)\n",
            "             ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 71, in _check_solver\n",
            "    raise ValueError(\n",
            "ValueError: Only 'saga' solver supports elasticnet penalty, got solver=liblinear.\n",
            "\n",
            "--------------------------------------------------------------------------------\n",
            "5 fits failed with the following error:\n",
            "Traceback (most recent call last):\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_validation.py\", line 866, in _fit_and_score\n",
            "    estimator.fit(X_train, y_train, **fit_params)\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/base.py\", line 1389, in wrapper\n",
            "    return fit_method(estimator, *args, **kwargs)\n",
            "           ^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^^\n",
            "  File \"/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_logistic.py\", line 1203, in fit\n",
            "    raise ValueError(\"l1_ratio must be specified when penalty is elasticnet.\")\n",
            "ValueError: l1_ratio must be specified when penalty is elasticnet.\n",
            "\n",
            "  warnings.warn(some_fits_failed_message, FitFailedWarning)\n",
            "/usr/local/lib/python3.11/dist-packages/sklearn/model_selection/_search.py:1108: UserWarning: One or more of the test scores are non-finite: [0.96666667 0.94166667        nan 0.95833333        nan        nan\n",
            "        nan 0.96666667        nan        nan]\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.multiclass import OneVsOneClassifier\n",
        "\n",
        "# Train One-vs-One Multiclass Logistic Regression\n",
        "ovo_model = OneVsOneClassifier(LogisticRegression(max_iter=1000))\n",
        "ovo_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred_ovo = ovo_model.predict(X_test)\n",
        "accuracy_ovo = accuracy_score(y_test, y_pred_ovo)\n",
        "print(\"One-vs-One (OvO) Multiclass Accuracy:\", accuracy_ovo)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sY5MjMtf4Q58",
        "outputId": "191cdc93-4cbc-4222-efe1-aad8012d1710"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "One-vs-One (OvO) Multiclass Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and plot confusion matrix\n",
        "y_pred = model.predict(X_test)\n",
        "cm = confusion_matrix(y_test, y_pred)\n",
        "ConfusionMatrixDisplay(cm).plot()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 449
        },
        "id": "txfuDIAV4S3W",
        "outputId": "22593089-1092-4e6a-a49a-c3d7a17ca340"
      },
      "execution_count": 16,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/plain": [
              "<Figure size 640x480 with 2 Axes>"
            ],
            "image/png": "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\n"
          },
          "metadata": {}
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import classification_report\n",
        "\n",
        "# Generate classification report\n",
        "report = classification_report(y_test, y_pred)\n",
        "print(\"Classification Report:\\n\", report)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "YX5NKzV-4T9o",
        "outputId": "48116fc5-1255-41e0-bbd4-5a3a97b7787d"
      },
      "execution_count": 17,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Classification Report:\n",
            "               precision    recall  f1-score   support\n",
            "\n",
            "           0       1.00      1.00      1.00        10\n",
            "           1       1.00      1.00      1.00         9\n",
            "           2       1.00      1.00      1.00        11\n",
            "\n",
            "    accuracy                           1.00        30\n",
            "   macro avg       1.00      1.00      1.00        30\n",
            "weighted avg       1.00      1.00      1.00        30\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model with balanced class weights\n",
        "balanced_model = LogisticRegression(class_weight='balanced', max_iter=1000)\n",
        "balanced_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred_balanced = balanced_model.predict(X_test)\n",
        "accuracy_balanced = accuracy_score(y_test, y_pred_balanced)\n",
        "print(\"Balanced Class Weight Accuracy:\", accuracy_balanced)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "QdgVuFI34VTF",
        "outputId": "0b6cd38f-179c-4e83-ef2f-3b94e6a53548"
      },
      "execution_count": 18,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Balanced Class Weight Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "from sklearn.impute import SimpleImputer\n",
        "\n",
        "# Load Titanic dataset\n",
        "titanic_df = pd.read_csv(\"titanic.csv\")\n",
        "\n",
        "# Handle missing values\n",
        "imputer = SimpleImputer(strategy='mean')\n",
        "titanic_df.fillna(imputer.fit_transform(titanic_df.select_dtypes(include=['number'])), inplace=True)\n",
        "\n",
        "# Define features and target\n",
        "X = titanic_df.drop(columns=['Survived'])\n",
        "y = titanic_df['Survived']\n",
        "\n",
        "# Train model\n",
        "titanic_model = LogisticRegression(max_iter=1000)\n",
        "titanic_model.fit(X, y)\n",
        "\n",
        "# Evaluate accuracy\n",
        "print(\"Titanic Dataset Accuracy:\", titanic_model.score(X, y))\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 373
        },
        "id": "2rFRTuQg4WqU",
        "outputId": "09e2572d-6b35-41c9-9b99-965ab61b0e2d"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "error",
          "ename": "FileNotFoundError",
          "evalue": "[Errno 2] No such file or directory: 'titanic.csv'",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mFileNotFoundError\u001b[0m                         Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-19-7b09ca35e607>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;31m# Load Titanic dataset\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m \u001b[0mtitanic_df\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mpd\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mread_csv\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"titanic.csv\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      6\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      7\u001b[0m \u001b[0;31m# Handle missing values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36mread_csv\u001b[0;34m(filepath_or_buffer, sep, delimiter, header, names, index_col, usecols, dtype, engine, converters, true_values, false_values, skipinitialspace, skiprows, skipfooter, nrows, na_values, keep_default_na, na_filter, verbose, skip_blank_lines, parse_dates, infer_datetime_format, keep_date_col, date_parser, date_format, dayfirst, cache_dates, iterator, chunksize, compression, thousands, decimal, lineterminator, quotechar, quoting, doublequote, escapechar, comment, encoding, encoding_errors, dialect, on_bad_lines, delim_whitespace, low_memory, memory_map, float_precision, storage_options, dtype_backend)\u001b[0m\n\u001b[1;32m   1024\u001b[0m     \u001b[0mkwds\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds_defaults\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1025\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1026\u001b[0;31m     \u001b[0;32mreturn\u001b[0m \u001b[0m_read\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1027\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1028\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_read\u001b[0;34m(filepath_or_buffer, kwds)\u001b[0m\n\u001b[1;32m    618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    619\u001b[0m     \u001b[0;31m# Create the parser.\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 620\u001b[0;31m     \u001b[0mparser\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mTextFileReader\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mfilepath_or_buffer\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    622\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0mchunksize\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0miterator\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(self, f, engine, **kwds)\u001b[0m\n\u001b[1;32m   1618\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1619\u001b[0m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandles\u001b[0m\u001b[0;34m:\u001b[0m \u001b[0mIOHandles\u001b[0m \u001b[0;34m|\u001b[0m \u001b[0;32mNone\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1620\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_engine\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_make_engine\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mengine\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1621\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1622\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;34m->\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/parsers/readers.py\u001b[0m in \u001b[0;36m_make_engine\u001b[0;34m(self, f, engine)\u001b[0m\n\u001b[1;32m   1878\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1879\u001b[0m                     \u001b[0mmode\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\"b\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1880\u001b[0;31m             self.handles = get_handle(\n\u001b[0m\u001b[1;32m   1881\u001b[0m                 \u001b[0mf\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1882\u001b[0m                 \u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/pandas/io/common.py\u001b[0m in \u001b[0;36mget_handle\u001b[0;34m(path_or_buf, mode, encoding, compression, memory_map, is_text, errors, storage_options)\u001b[0m\n\u001b[1;32m    871\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mencoding\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"b\"\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    872\u001b[0m             \u001b[0;31m# Encoding\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 873\u001b[0;31m             handle = open(\n\u001b[0m\u001b[1;32m    874\u001b[0m                 \u001b[0mhandle\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    875\u001b[0m                 \u001b[0mioargs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmode\u001b[0m\u001b[0;34m,\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mFileNotFoundError\u001b[0m: [Errno 2] No such file or directory: 'titanic.csv'"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "\n",
        "# Apply Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train model without scaling\n",
        "model_no_scaling = LogisticRegression(max_iter=1000)\n",
        "model_no_scaling.fit(X_train, y_train)\n",
        "acc_no_scaling = model_no_scaling.score(X_test, y_test)\n",
        "\n",
        "# Train model with scaling\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "acc_scaled = model_scaled.score(X_test_scaled, y_test)\n",
        "\n",
        "print(\"Accuracy Without Scaling:\", acc_no_scaling)\n",
        "print(\"Accuracy With Scaling:\", acc_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "dvbM4XA74XyZ",
        "outputId": "e98a8d02-0a4c-4d78-c1fc-300135dc7bf6"
      },
      "execution_count": 20,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy Without Scaling: 1.0\n",
            "Accuracy With Scaling: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import roc_auc_score\n",
        "\n",
        "# Predict probabilities for ROC-AUC calculation\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute ROC-AUC score\n",
        "roc_auc = roc_auc_score(y_test, y_probs)\n",
        "print(\"ROC-AUC Score:\", roc_auc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "IGRlp8Yw4ZcF",
        "outputId": "fb7786f4-1bbb-431b-905d-488bec806822"
      },
      "execution_count": 21,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "multi_class must be in ('ovo', 'ovr')",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-21-91407b5d2a62>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      5\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      6\u001b[0m \u001b[0;31m# Compute ROC-AUC score\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 7\u001b[0;31m \u001b[0mroc_auc\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mroc_auc_score\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m      8\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"ROC-AUC Score:\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mroc_auc\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mroc_auc_score\u001b[0;34m(y_true, y_score, average, sample_weight, max_fpr, multi_class, labels)\u001b[0m\n\u001b[1;32m    632\u001b[0m             )\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmulti_class\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"raise\"\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"multi_class must be in ('ovo', 'ovr')\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         return _multiclass_roc_auc_score(\n\u001b[1;32m    636\u001b[0m             \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mlabels\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmulti_class\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0maverage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multi_class must be in ('ovo', 'ovr')"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# Train model with custom regularization parameter C=0.5\n",
        "custom_model = LogisticRegression(C=0.5, max_iter=1000)\n",
        "custom_model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and evaluate accuracy\n",
        "y_pred_custom = custom_model.predict(X_test)\n",
        "accuracy_custom = accuracy_score(y_test, y_pred_custom)\n",
        "print(\"Custom Learning Rate (C=0.5) Accuracy:\", accuracy_custom)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "Yv6enD9M4a1G",
        "outputId": "4cb07250-3815-4bc6-8852-b7d9c183ceef"
      },
      "execution_count": 23,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Custom Learning Rate (C=0.5) Accuracy: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np\n",
        "\n",
        "# Train model\n",
        "feature_model = LogisticRegression(max_iter=1000)\n",
        "feature_model.fit(X_train, y_train)\n",
        "\n",
        "# Get feature importance\n",
        "feature_importance = np.abs(feature_model.coef_).flatten()\n",
        "feature_names = data.feature_names  # Change this for real dataset\n",
        "sorted_idx = np.argsort(feature_importance)[::-1]\n",
        "\n",
        "# Print top features\n",
        "print(\"Top Important Features:\")\n",
        "for i in sorted_idx:\n",
        "    print(f\"{feature_names[i]}: {feature_importance[i]}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 193
        },
        "id": "gGWHFnDy4dhn",
        "outputId": "73fffcd8-73a2-4614-d15b-97bdeca4d990"
      },
      "execution_count": 24,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Top Important Features:\n"
          ]
        },
        {
          "output_type": "error",
          "ename": "IndexError",
          "evalue": "list index out of range",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-24-5eb6bce5f850>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     13\u001b[0m \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"Top Important Features:\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     14\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mi\u001b[0m \u001b[0;32min\u001b[0m \u001b[0msorted_idx\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 15\u001b[0;31m     \u001b[0mprint\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34mf\"{feature_names[i]}: {feature_importance[i]}\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
            "\u001b[0;31mIndexError\u001b[0m: list index out of range"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import cohen_kappa_score\n",
        "\n",
        "# Compute Cohen's Kappa score\n",
        "kappa_score = cohen_kappa_score(y_test, y_pred)\n",
        "print(\"Cohen's Kappa Score:\", kappa_score)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vzOuGZ-s4emB",
        "outputId": "0dd4a5f5-bfe3-4f4f-abfc-54f37fd6b0af"
      },
      "execution_count": 26,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Cohen's Kappa Score: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "from sklearn.metrics import precision_recall_curve\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict probabilities\n",
        "y_probs = model.predict_proba(X_test)[:, 1]\n",
        "\n",
        "# Compute precision-recall values\n",
        "precision, recall, _ = precision_recall_curve(y_test, y_probs)\n",
        "\n",
        "# Plot Precision-Recall Curve\n",
        "plt.plot(recall, precision, marker='.', label=\"Logistic Regression\")\n",
        "plt.xlabel(\"Recall\")\n",
        "plt.ylabel(\"Precision\")\n",
        "plt.title(\"Precision-Recall Curve\")\n",
        "plt.legend()\n",
        "plt.show()\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 356
        },
        "id": "eWH__frj4fao",
        "outputId": "8aceafb7-177f-475f-a6aa-39860c829a50"
      },
      "execution_count": 27,
      "outputs": [
        {
          "output_type": "error",
          "ename": "ValueError",
          "evalue": "multiclass format is not supported",
          "traceback": [
            "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
            "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
            "\u001b[0;32m<ipython-input-27-d832e177c85d>\u001b[0m in \u001b[0;36m<cell line: 0>\u001b[0;34m()\u001b[0m\n\u001b[1;32m     11\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     12\u001b[0m \u001b[0;31m# Compute precision-recall values\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 13\u001b[0;31m \u001b[0mprecision\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecall\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0m_\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprecision_recall_curve\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_test\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_probs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     14\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     15\u001b[0m \u001b[0;31m# Plot Precision-Recall Curve\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/utils/_param_validation.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    214\u001b[0m                     )\n\u001b[1;32m    215\u001b[0m                 ):\n\u001b[0;32m--> 216\u001b[0;31m                     \u001b[0;32mreturn\u001b[0m \u001b[0mfunc\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    217\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mInvalidParameterError\u001b[0m \u001b[0;32mas\u001b[0m \u001b[0me\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    218\u001b[0m                 \u001b[0;31m# When the function is just a wrapper around an estimator, we allow\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36mprecision_recall_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight, drop_intermediate, probas_pred)\u001b[0m\n\u001b[1;32m   1003\u001b[0m         \u001b[0my_score\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mprobas_pred\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1004\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1005\u001b[0;31m     fps, tps, thresholds = _binary_clf_curve(\n\u001b[0m\u001b[1;32m   1006\u001b[0m         \u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mpos_label\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mpos_label\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0msample_weight\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1007\u001b[0m     )\n",
            "\u001b[0;32m/usr/local/lib/python3.11/dist-packages/sklearn/metrics/_ranking.py\u001b[0m in \u001b[0;36m_binary_clf_curve\u001b[0;34m(y_true, y_score, pos_label, sample_weight)\u001b[0m\n\u001b[1;32m    816\u001b[0m     \u001b[0my_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtype_of_target\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0minput_name\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"y_true\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    817\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"binary\"\u001b[0m \u001b[0;32mor\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"multiclass\"\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0mpos_label\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 818\u001b[0;31m         \u001b[0;32mraise\u001b[0m \u001b[0mValueError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m\"{0} format is not supported\"\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mformat\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_type\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    819\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    820\u001b[0m     \u001b[0mcheck_consistent_length\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0my_true\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0my_score\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
            "\u001b[0;31mValueError\u001b[0m: multiclass format is not supported"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "solvers = ['liblinear', 'saga', 'lbfgs']\n",
        "for solver in solvers:\n",
        "    model = LogisticRegression(solver=solver, max_iter=1000)\n",
        "    model.fit(X_train, y_train)\n",
        "    accuracy = model.score(X_test, y_test)\n",
        "    print(f\"Accuracy with solver '{solver}': {accuracy}\")\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XlYBd_6g4416",
        "outputId": "92d6f3de-a471-4086-f6e6-f925d7d33729"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy with solver 'liblinear': 1.0\n",
            "Accuracy with solver 'saga': 1.0\n",
            "Accuracy with solver 'lbfgs': 1.0\n"
          ]
        },
        {
          "output_type": "stream",
          "name": "stderr",
          "text": [
            "/usr/local/lib/python3.11/dist-packages/sklearn/linear_model/_sag.py:348: ConvergenceWarning: The max_iter was reached which means the coef_ did not converge\n",
            "  warnings.warn(\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.metrics import matthews_corrcoef\n",
        "\n",
        "# Train logistic regression model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Predict and compute MCC\n",
        "y_pred = model.predict(X_test)\n",
        "mcc = matthews_corrcoef(y_test, y_pred)\n",
        "print(\"Matthews Correlation Coefficient (MCC):\", mcc)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "aBP6TM-s46HU",
        "outputId": "c90b4fdd-625b-4a0c-ca8a-281a32680b88"
      },
      "execution_count": 29,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Matthews Correlation Coefficient (MCC): 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.preprocessing import StandardScaler\n",
        "from sklearn.metrics import accuracy_score\n",
        "\n",
        "# Train model on raw data\n",
        "model_raw = LogisticRegression(max_iter=1000)\n",
        "model_raw.fit(X_train, y_train)\n",
        "accuracy_raw = model_raw.score(X_test, y_test)\n",
        "\n",
        "# Apply Standardization\n",
        "scaler = StandardScaler()\n",
        "X_train_scaled = scaler.fit_transform(X_train)\n",
        "X_test_scaled = scaler.transform(X_test)\n",
        "\n",
        "# Train model on standardized data\n",
        "model_scaled = LogisticRegression(max_iter=1000)\n",
        "model_scaled.fit(X_train_scaled, y_train)\n",
        "accuracy_scaled = model_scaled.score(X_test_scaled, y_test)\n",
        "\n",
        "print(\"Accuracy on Raw Data:\", accuracy_raw)\n",
        "print(\"Accuracy on Standardized Data:\", accuracy_scaled)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "X-hm859G4724",
        "outputId": "82683cbb-bd3a-468b-fe69-ef0b9103c36d"
      },
      "execution_count": 30,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Accuracy on Raw Data: 1.0\n",
            "Accuracy on Standardized Data: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from sklearn.model_selection import cross_val_score\n",
        "import numpy as np\n",
        "\n",
        "# Define different C values\n",
        "C_values = [0.01, 0.1, 1, 10, 100]\n",
        "best_C = None\n",
        "best_score = 0\n",
        "\n",
        "# Perform cross-validation for each C value\n",
        "for C in C_values:\n",
        "    model = LogisticRegression(C=C, max_iter=1000)\n",
        "    scores = cross_val_score(model, X_train, y_train, cv=5)\n",
        "    avg_score = np.mean(scores)\n",
        "\n",
        "    print(f\"C={C}, Cross-Validation Accuracy: {avg_score}\")\n",
        "\n",
        "    if avg_score > best_score:\n",
        "        best_score = avg_score\n",
        "        best_C = C\n",
        "\n",
        "print(\"Optimal C:\", best_C)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C3fiZN-r4937",
        "outputId": "a44737f9-f21e-434c-a959-01de10ae5e71"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "C=0.01, Cross-Validation Accuracy: 0.8583333333333334\n",
            "C=0.1, Cross-Validation Accuracy: 0.9333333333333333\n",
            "C=1, Cross-Validation Accuracy: 0.9666666666666666\n",
            "C=10, Cross-Validation Accuracy: 0.9416666666666667\n",
            "C=100, Cross-Validation Accuracy: 0.95\n",
            "Optimal C: 1\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import joblib\n",
        "\n",
        "# Train model\n",
        "model = LogisticRegression(max_iter=1000)\n",
        "model.fit(X_train, y_train)\n",
        "\n",
        "# Save model to a file\n",
        "joblib.dump(model, \"logistic_regression_model.pkl\")\n",
        "print(\"Model saved successfully.\")\n",
        "\n",
        "# Load model from file\n",
        "loaded_model = joblib.load(\"logistic_regression_model.pkl\")\n",
        "\n",
        "# Predict using loaded model\n",
        "y_pred_loaded = loaded_model.predict(X_test)\n",
        "accuracy_loaded = accuracy_score(y_test, y_pred_loaded)\n",
        "print(\"Accuracy of Loaded Model:\", accuracy_loaded)\n"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "ecU2CxDC4-pQ",
        "outputId": "f92714ab-f445-4c77-c6f8-048bc60ac8b5"
      },
      "execution_count": 33,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Model saved successfully.\n",
            "Accuracy of Loaded Model: 1.0\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "lfLe85Gl5ElU"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}